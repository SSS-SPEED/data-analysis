
Beautiful Soup:


总结：
推荐使用lxml解析库，必要时使用html.parser。
节点选择筛选功能弱但是速度快。
建议使用find()或者find_all()查询匹配单个结果或者多个结果。
如果对CSS选择器熟悉的话，可以使用select()方法选择。



简单来说，Beautiful Soup就是Python的一个HTML或XML的解析库，可以用它来方便地从网页中提取数据。
特点：
提供一些简单的、Python式的函数来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据。
Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为UTF-8编码。
已成为和lxml、html6lib一样出色的Python解释器，为用户灵活地提供不同的解析策略或强劲的速度。


Beautiful Soup在解析时实际上依赖解析器

以下是4种解析器：
BeautifulSoup(markup, "html.parser")      Python标准库
BeautifulSoup(markup, "lxml")             lxml HTML解析器      lxml解析器有解析HTML和XML的功能，而且速度快，容错能力强，推荐使用
BeautifulSoup(markup, "xml")              lxml XML解析器
BeautifulSoup(markup, "html5lib")         html5lib


from bs4 import BeautifulSoup
soup = BeautifulSoup('<p>Hello</p>', 'lxml')       # 使用了lxml解析器
print(soup.p.string)                               # 解析出了Hello


soup.prettify()         # 这个方法可以把要解析的字符串以标准的缩进格式输出
soup.title              # 输出含<title>标签的完整内容，例如<title>The Dormouse's story</title>
soup.title.string       # 仅输出了title节点的内容，例如The Dormouse's story


//////////////////////////// 基本用法 ////////////////////////////

from bs4 import BeautifulSoup

html = """                                                                                     # 这个HTML不完整，缺闭合的<body>等
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1"><!-- Elsie --></a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
soup = BeautifulSoup(html, 'lxml')              # 实例化BeautifulSoup的时候，会自动补全HTML代码，使用了lxml解析器
print(soup.prettify())                          # 这个方法可以把要解析的字符串以标准的缩进格式输出
print(soup.title.string)                        # 输出HTML中title节点的文本内容
print(soup.title)                               # 连带着title节点字段一起输出
print(soup.p)                                   # 输出第一个符合的P字段

获得节点名称
print(soup.title.name)                # 输出title，因为节点名称就是title
获取节点属性
print(soup.p.attrs)                   # 输出{'class': ['title'], 'name': 'dromouse'}
                                      # 字典类型，同样是默认的第一个P节点
print(soup.p.attrs['name'])           # 输出dromouse，指定搜索P节点的name属性的值
print(soup.p['class'])                # 上面那种写法的简介形式
                                      # 注意的是，若name属性值唯一，则返回就是字符串，若有多个class，则返回列表
获取内容
print(soup.p.string)                  # 输出The Dormouse's story，若P里面有2对<b>，则返回None
print(soup.head.title.string)         # 输出The Dormouse's story，多级节点，一级一级的找

html = """
<html>
    <head>
        <title>The Dormouse's story</title>
    </head>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
            <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> 
            and
            <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>
            and they lived at the bottom of a well.
        </p>
        <p class="story">...</p>
"""

获取直接子节点
print(soup.p.contents)                # 返回了列表形式，有3段P的内容，有3个直接子节点a，和2个a之间的空
                                      # 其中第一个子节点a里有span节点，contents并没有剥离出来，而是与a一起打印出来
print(soup.p.children)                # 同样是获取直接子节点，但返回生成器类型
for i, child in enumerate(soup.p.children):
    print(i, child)

获取所有的子孙节点
print(soup.p.descendants)             # 返回生成器类型
for i, child in enumerate(soup.p.descendants):         # i是计数器，child是内容
    print(i, child)

获取父节点
print(soup.a.parent)                  # 输出的是p节点及其内部的内容

获取祖先节点
for i, parent in enumerate(soup.a.parents):      # 返回生成器类型，输出的是<p>，<body>，<html>
    print(i, parent)

获取兄弟节点
print('Next Sibling', soup.a.next_sibling)                          # 输出空，因为是a节点的下一个兄弟节点，两个子节点之间内容就是空
print('Prev Sibling', soup.a.previous_sibling)                      # 输出内容，内容与子节点是同级关系
print('Next Siblings', list(enumerate(soup.a.next_siblings)))       # 返回下一批兄弟节点生成器类型
print('Prev Siblings', list(enumerate(soup.a.previous_siblings)))   # 返回上一批兄弟节点生成器类型


提取信息内容

html = """
<html>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">Bob</a><a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> 
        </p>
"""
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print('Next Sibling:') 
print(soup.a.next_sibling)                       # a节点的下一个兄弟节点，就是下一个a节点的全部
print(soup.a.next_sibling.string)                # a节点的下一个兄弟节点的内容，就是下一个a节点的内容Lacie
print('Parent:')
print(type(soup.a.parents))                      # 生成器类型
print(list(soup.a.parents)[0])                   # a的祖先节点依次是p,body,html，所以[0]是P节点的全部
print(list(soup.a.parents)[0].attrs['class'])    # 获得P节点的属性class的值，所以是列表类型的story



//////////////////////////// 方法选择器 ////////////////////////////

find_all()
查询所有符合条件的元素。给它传入一些属性或文本，就可以得到符合条件的元素
find_all(name , attrs , recursive , text , **kwargs)

注意：
find()                                                   该函数返回的是单个元素，也就是第一个匹配的元素
find_parents()和find_parent()：                          前者返回所有祖先节点，后者返回直接父节点。
find_next_siblings()和find_next_sibling()：              前者返回后面所有的兄弟节点，后者返回后面第一个兄弟节点。
find_previous_siblings()和find_previous_sibling()：      前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点。
find_all_next()和find_next()：                           前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。
find_all_previous()和find_previous()：                   前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。

html='''
<div class="panel">
    <div class="panel-heading">
        <h4>Hello</h4>
    </div>
    <div class="panel-body">
        <ul class="list" id="list-1">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
            <li class="element">Jay</li>
        </ul>
        <ul class="list list-small" id="list-2">
            <li class="element">Foo1</li>
            <li class="element">Bar2</li>
        </ul>
    </div>
</div>
'''
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')


☆☆☆☆☆☆  name参数
print(soup.find_all(name='ul'))                  # 找寻所有的叫做ul的节点
print(soup.find_all(name='ul')[0])               # 返回其实是一个列表

for ul in soup.find_all(name='ul'):              # 获得所有ul节点的列表
    for li in ul.find_all(name='li'):            # 遍历每一个ul节点，找里面叫做的li的节点，同样返回是li节点的数组
        print(li.string)                         # 输出每一个li节点的内容

Foo
Bar
Jay
Foo1
Ba2


☆☆☆☆☆☆  attrs参数
print(soup.find_all(attrs={'id': 'list-1'}))         # 找寻属性有id，并且值是list-1的节点，返回数组，返回是第一个ul的全部
print(soup.find_all(attrs={'name': 'elements'}))     # 找寻属性有name，并且值是elements的节点，返回数组，发现是空，返回就是[]
print(soup.find_all(id='list-1'))                    # 简洁形式，返回是列表，第一个ul的全部
print(soup.find_all(class_='element'))               # 简洁形式，返回是列表，5个li的全部

注意：class在Python里是一个关键字，所以后面需要加一个下划线，即class_='element'，反正关键字颜色不一样的


☆☆☆☆☆☆  text参数
text参数可用来匹配节点的文本，传入的形式可以是字符串，可以是正则表达式对象

import re
html='''
<div class="panel">
    <div class="panel-body">
        <a>Hello, this is a link</a>
        <a>Hello, this is a link, too</a>
    </div>
</div>
'''
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.find_all(text=re.compile('link')))      # 搜找所有含有'link'内容的每个节点的内容



//////////////////////////// CSS选择器 ////////////////////////////

要复习CSS的选择器相关知识

html='''
<div class="panel">
    <div class="panel-heading">
        <h4>Hello</h4>
    </div>
    <div class="panel-body">
        <ul class="list" id="list-1">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
            <li class="element">Jay</li>
        </ul>
        <ul class="list list-small" id="list-2">
            <li class="element">Foo</li>
            <li class="element">Bar</li>
        </ul>
    </div>
</div>
'''
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.select('.panel .panel-heading'))    # 找继承class属性为panel的，并且自身是panel-heading的节点
                                               # 输出是那个<div class="panel-heading">的全部
print(soup.select('ul li'))                    # 找所有ul下的所有li，有5个
print(soup.select('#list-2 .element'))         # 找继承了id="list-2"的，自身class属性为element的节点，有2个

for ul in soup.select('ul'):                   # 找所有的ul节点
    print(ul.select('li'))                     # 输出每个ul节点下的每一个li节点，每次返回是数组

for ul in soup.select('ul'):                   # 找所有的ul节点
    print(ul['id'])                            # 打印每个ul节点的id的值
    print(ul.attrs['id'])                      # 输出同上，就是一个方法

for li in soup.select('li'):                   # 找所有的li节点
    print(li.get_text())                       # 打印每个li节点的内容
    print(li.string)                           # 输出同上，就是一个方法















































































































































